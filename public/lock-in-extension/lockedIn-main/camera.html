<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>LockedIn - Live Camera Mode</title>
    <script type="module" src="https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.3/vision_bundle.js"></script>
    <style>
        :root {
            --background-color: #1a1a1a;
            --primary-color: #e53935;
            --text-color: #f5f5f5;
            --button-hover-color: #c62828;
            --input-bg-color: #333;
        }
        body {
            background-color: var(--background-color);
            color: var(--text-color);
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif;
            display: flex;
            flex-direction: column;
            justify-content: center;
            align-items: center;
            height: 100vh;
            margin: 0;
            text-align: center;
        }
        h1 {
            color: var(--primary-color);
            text-transform: uppercase;
            letter-spacing: 2px;
        }
        #video-container {
            position: relative;
            width: 640px;
            height: 480px;
            border-radius: 10px;
            overflow: hidden;
            background-color: #000;
            box-shadow: 0 5px 15px rgba(0,0,0,0.3);
        }
        video {
            width: 100%;
            height: 100%;
            transform: scaleX(-1); /* Mirror view */
        }
        .controls {
            display: flex;
            align-items: center;
            margin-top: 20px;
            gap: 10px;
        }
        .button {
            background-color: var(--primary-color);
            color: var(--text-color);
            border: none;
            padding: 10px 20px;
            border-radius: 5px;
            font-size: 1em;
            cursor: pointer;
            transition: background-color 0.3s ease;
        }
        .button:hover:not(:disabled) {
            background-color: var(--button-hover-color);
        }
        .button:disabled {
            cursor: not-allowed;
            opacity: 0.6;
        }
        #videoPrompt {
            padding: 10px;
            border-radius: 5px;
            border: 1px solid var(--primary-color);
            background-color: var(--input-bg-color);
            color: var(--text-color);
            font-size: 1em;
            width: 300px;
        }
        #status {
            margin-top: 15px;
            font-size: 1.1em;
            color: #bdbdbd;
            height: 20px;
        }
        a {
            color: var(--primary-color);
            position: absolute;
            top: 20px;
            left: 20px;
        }
    </style>
</head>
<body>
    <a href="index.html">&lt; Back to Hub</a>
    <h1>Live Camera Mode</h1>
    <div id="video-container">
        <video id="webcam" autoplay playsinline></video>
        <canvas id="frameCanvas" style="display: none;"></canvas>
    </div>
    <div id="status">Initializing...</div>
    <div class="controls">
        <button id="roastButton" class="button" disabled>Roast Me</button>
        <input type="text" id="videoPrompt" placeholder="Ask about what you see...">
        <button id="askVideoButton" class="button" disabled>Ask Gemini Vision</button>
    </div>

    <script type="module">
        const { FaceDetector, FilesetResolver } = await import("https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.3/vision_bundle.js");

        const video = document.getElementById("webcam");
        const statusDiv = document.getElementById("status");
        const roastButton = document.getElementById("roastButton");
        const askVideoButton = document.getElementById("askVideoButton");
        const videoPrompt = document.getElementById("videoPrompt");
        const canvas = document.getElementById("frameCanvas");
        const ctx = canvas.getContext('2d');

        const GEMINI_API_KEY = "AIzaSyCbdJGSzUMDHYEjme05PVUDo6WrcxeNanc";
        let faceDetector;
        let lastPresence = false;

        async function setupFaceDetector() {
            const vision = await FilesetResolver.forVisionTasks("https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.3/wasm");
            faceDetector = await FaceDetector.createFromOptions(vision, {
                baseOptions: {
                    modelAssetPath: "https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite",
                    delegate: "GPU"
                },
                runningMode: "VIDEO"
            });
            statusDiv.textContent = "Face detector ready.";
            enableCamera();
        }

        async function enableCamera() {
            if (!navigator.mediaDevices?.getUserMedia) {
                statusDiv.textContent = "getUserMedia() is not supported by your browser.";
                return;
            }
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ video: true });
                video.srcObject = stream;
                video.onloadedmetadata = () => {
                    video.play();
                    predictWebcam(); // Start MediaPipe loop
                };
            } catch (err) {
                console.error("Error accessing webcam: ", err);
                statusDiv.textContent = "Error: Webcam access denied.";
            }
        }

        let lastVideoTime = -1;
        async function predictWebcam() {
            if (video.readyState < 2) { // Wait for video to be ready
                 window.requestAnimationFrame(predictWebcam);
                 return;
            }
            if (video.currentTime !== lastVideoTime) {
                lastVideoTime = video.currentTime;
                const detections = faceDetector.detectForVideo(video, performance.now());
                const isPresent = detections.detections.length > 0;
                
                if (isPresent !== lastPresence) {
                    lastPresence = isPresent;
                    // Only update status if an API call isn't in progress
                    if (!roastButton.disabled && !askVideoButton.disabled) {
                       statusDiv.textContent = isPresent ? "User is present." : "User is not present.";
                    }
                    console.log("User presence (via MediaPipe):", isPresent);
                }
            }
            window.requestAnimationFrame(predictWebcam);
        }
        
        function speak(text) {
            window.speechSynthesis.cancel(); // Cancel any previous speech
            if ('speechSynthesis' in window) {
                const utterance = new SpeechSynthesisUtterance(text);
                utterance.rate = 1.1;
                utterance.pitch = 0.9;
                window.speechSynthesis.speak(utterance);
            } else {
                alert("Speech synthesis not supported in this browser.");
            }
        }
        
        function setButtonsDisabled(disabled) {
             roastButton.disabled = disabled;
             askVideoButton.disabled = disabled;
        }

        async function callGemini(prompt, base64Data = null) {
            setButtonsDisabled(true);
            const buttonText = base64Data ? "Asking Gemini..." : "Getting a roast...";
            const originalButton = base64Data ? askVideoButton : roastButton;
            originalButton.textContent = buttonText;
            statusDiv.textContent = "Calling Gemini API...";

            let contents = [{ parts: [{ text: prompt }] }];
            if (base64Data) {
                contents[0].parts.push({
                    inline_data: {
                        mime_type: "image/jpeg",
                        data: base64Data
                    }
                });
            }

            try {
                const response = await fetch(`https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash-latest:generateContent?key=${GEMINI_API_KEY}`, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({ contents })
                });

                if (!response.ok) {
                    const errorData = await response.json();
                    console.error("API Error Response:", errorData);
                    throw new Error(`API call failed: ${errorData.error.message}`);
                }

                const data = await response.json();
                if (data.candidates && data.candidates.length > 0) {
                    const resultText = data.candidates[0].content.parts[0].text;
                    statusDiv.textContent = "Response received!";
                    speak(resultText.trim());
                } else {
                    throw new Error("No valid candidates received from API.");
                }

            } catch (error) {
                console.error("Error calling Gemini:", error);
                statusDiv.textContent = "Error: " + error.message;
                speak("There was an error with the request. Check the console for details.");
            } finally {
                setButtonsDisabled(false);
                askVideoButton.textContent = "Ask Gemini Vision";
                roastButton.textContent = "Roast Me";
                if (isPresent) statusDiv.textContent = "User is present.";
            }
        }
        
        roastButton.addEventListener('click', () => {
            const roastPrompt = "You are a sarcastic comedian. Deliver a roast about my productivity, or lack thereof. Keep it witty and sharp, but not truly mean. Intensity: 6/10.";
            callGemini(roastPrompt);
        });

        askVideoButton.addEventListener('click', () => {
            const prompt = videoPrompt.value;
            if (!prompt) {
                speak("Please type a question in the box first.");
                return;
            }
            
            // Capture a frame
            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;
            ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
            
            // Get base64 representation (remove data:image/jpeg;base64,)
            const base64Data = canvas.toDataURL('image/jpeg').split(',')[1];
            
            callGemini(prompt, base64Data);
        });

        video.oncanplay = () => {
            setButtonsDisabled(false);
            statusDiv.textContent = "Ready.";
        };

        setupFaceDetector();
    </script>
</body>
</html>
